{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6b3bc8",
   "metadata": {},
   "source": [
    "# LLM Evaluation 중요성\n",
    "\n",
    "서비스 안정적으로 운영하기 위해.\n",
    "\n",
    "사용자가 정확한 정보를 받을 수 있는지 확인\n",
    "\n",
    "할루시네이션으로 인해 LLM이 잘못된 정보를 생성하는 경우가 있다.\n",
    "(ex. 세금 답변을 잘못주어 사용자가 잘못된 결과를 초래할 수 있다.)\n",
    "\n",
    "# Dataset?\n",
    "- 도메인 전문가가 작성한 정답지\n",
    "- 특정 질문이 들어오면 ~한 답변을 해야한다\n",
    "- ex. 1+1 = 2 라는 것을 미리 정의\n",
    "\n",
    "# 낮은 점수 (70점대)\n",
    "- 정답지가 틀렸을 수 있다.\n",
    "- embedding 효율이 떨어져 retrieval된 문서가 잘못돼서 문제가 발생한 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f1c220",
   "metadata": {},
   "source": [
    "# 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7f8ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langsmith in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (0.6.9)\n",
      "Requirement already satisfied: openai in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (1.2.10)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (1.1.9)\n",
      "Requirement already satisfied: langchain-pinecone in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (0.2.13)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (3.11.7)\n",
      "Requirement already satisfied: pydantic<3,>=2 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (2.12.5)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (0.14.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (0.25.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (2.32.5)\n",
      "Requirement already satisfied: xxhash>=3.0.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (3.6.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (24.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (4.12.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (4.67.3)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from openai) (0.13.0)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.10 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (1.2.13)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain) (1.0.8)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: simsimd>=5.9.11 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain-pinecone) (6.5.12)\n",
      "Requirement already satisfied: numpy!=2.0.2,>=1.26.4 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain-pinecone) (2.2.6)\n",
      "Requirement already satisfied: pinecone[asyncio]<8.0.0,>=6.0.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain-pinecone) (7.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (9.1.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (6.0.3)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.10->langchain) (1.33)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.7)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.4)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.8.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (0.0.7)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohttp-retry<3.0.0,>=2.9.1 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.9.1)\n",
      "Requirement already satisfied: aiohttp>=3.9.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (3.13.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pydantic<3,>=2->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pydantic<3,>=2->langsmith) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pydantic<3,>=2->langsmith) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.0.0->langsmith) (3.4.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: colorama in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (25.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (0.4.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.8.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.22.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (6.7.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.4.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.10->langchain) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone[asyncio]<8.0.0,>=6.0.0->langchain-pinecone) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 26.0.1\n",
      "[notice] To update, run: c:\\Users\\hanjo\\.pyenv\\pyenv-win\\versions\\3.10.11\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langsmith openai python-dotenv langchain langchain-openai langchain-pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f382bb93",
   "metadata": {},
   "source": [
    "2. 데이터 생성\n",
    "Evaluation에 활용될 Question - Answer pair 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdda10e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'example_ids': ['3ceaaace-d86e-4aa4-bf22-4d8824e611d2',\n",
       "  '83bc8832-13b5-4b90-aad6-359423fc01b9',\n",
       "  '8787a36f-764b-47ca-a9ca-02f51b1c5bc1',\n",
       "  '6a62f373-fb0c-4d36-89fe-b1c60b63d98d',\n",
       "  '062d1a24-2815-4a67-8c8f-acf0fee6c78e',\n",
       "  '5dd48c38-28bf-467e-9839-d6745c06fab2',\n",
       "  'd8c27ec5-aad8-4d0a-81ed-4b755360ba4d',\n",
       "  '08b58b41-bba7-4bd4-a307-1ed57e2da1d2',\n",
       "  'b8c2f139-b43f-434e-bc18-4626b034034e',\n",
       "  'a83e815a-66f1-40bf-84b2-f27cd0c601e0',\n",
       "  '492355b8-c986-4e5c-890b-589e8be19280',\n",
       "  '25248693-a71b-45a3-a9d4-34cfdffed60a',\n",
       "  'c4556fe3-8b66-4662-9a7f-3f75ffa0bf29',\n",
       "  '7a5048c4-c696-435b-aa81-ed195001aa1d',\n",
       "  'd4a6c6ce-8172-4fc5-ac29-c13bf5e05a06',\n",
       "  'c569f8fd-4daa-42c1-96e0-8cd92a015788',\n",
       "  'a23df803-77c6-41ee-be9a-febaffdfd586',\n",
       "  '0cafc666-31cc-4218-ba7a-986fc33965fa',\n",
       "  'ec66fbb7-22df-4d7b-9c34-1e824b1f329f',\n",
       "  '4f76750e-d0b2-43b7-96d8-73829c7b3d6e'],\n",
       " 'count': 20,\n",
       " 'as_of': '2026-02-22T07:21:50.969856458Z'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "client.create_examples(\n",
    "    inputs=[\n",
    "        {\"input_question\": \"제1조에 따른 소득세법의 목적은 무엇인가요?\"},\n",
    "        {\"input_question\": \"'거주자'는 소득세법에서 어떻게 정의되나요?\"},\n",
    "        {\"input_question\": \"'비거주자'는 소득세법에 따라 어떻게 정의되나요?\"},\n",
    "        {\"input_question\": \"소득세법에 따른 '내국법인'은 누구를 의미하나요?\"},\n",
    "        {\"input_question\": \"소득세법에 따라 소득세를 납부할 의무가 있는 사람은 누구인가요?\"},\n",
    "        {\"input_question\": \"거주자의 과세 범위는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세법에 따라 소득은 어떻게 분류되나요?\"},\n",
    "        {\"input_question\": \"종합소득이란 무엇인가요?\"},\n",
    "        {\"input_question\": \"세금이 면제되는 소득의 종류는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세의 과세기간은 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"거주자의 소득세 납세지는 어디인가요?\"},\n",
    "        {\"input_question\": \"비거주자의 소득세 납세지는 어디인가요?\"},\n",
    "        {\"input_question\": \"납세지가 불분명한 경우 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"원천징수세액의 납세지는 어떻게 결정되나요?\"},\n",
    "        {\"input_question\": \"납세자의 사망 시 납세지는 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"신탁 소득에 대한 납세의 범위는 무엇인가요?\"},\n",
    "        {\"input_question\": \"원천징수 대상 소득은 무엇인가요?\"},\n",
    "        {\"input_question\": \"공동 소유 자산의 양도소득은 어떻게 과세되나요?\"},\n",
    "        {\"input_question\": \"이자 소득의 출처는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세법에서 배당소득은 어떻게 정의되나요?\"}\n",
    "    ],\n",
    "    outputs=[\n",
    "        {\"output_answer\": \"소득세법의 목적은 소득의 성격과 납세자의 부담능력에 따라 적정하게 과세함으로써 조세부담의 형평을 도모하고 재정수입의 원활한 조달에 이바지하는 것입니다.\"},\n",
    "        {\"output_answer\": \"'거주자'는 한국에 주소를 두거나 183일 이상 거소를 둔 개인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"'비거주자'는 거주자가 아닌 개인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"'내국법인'은 법인세법 제2조 제1호에 따른 내국법인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"거주자 및 국내원천소득이 있는 비거주자는 소득세를 납부할 의무가 있습니다.\"},\n",
    "        {\"output_answer\": \"거주자는 법에서 규정한 모든 소득에 대해 과세되며, 비거주자는 국내원천소득에 대해서만 과세됩니다.\"},\n",
    "        {\"output_answer\": \"소득은 종합소득, 퇴직소득, 양도소득으로 분류됩니다.\"},\n",
    "        {\"output_answer\": \"종합소득은 이자소득, 배당소득, 사업소득, 근로소득, 연금소득 및 기타소득을 포함합니다.\"},\n",
    "        {\"output_answer\": \"비과세 소득에는 공익신탁의 이익, 특정 사업소득 및 기타 법에서 정한 특정 소득이 포함됩니다.\"},\n",
    "        {\"output_answer\": \"소득세의 과세기간은 매년 1월 1일부터 12월 31일까지입니다.\"},\n",
    "        {\"output_answer\": \"거주자의 소득세 납세지는 주소지이며, 주소지가 없으면 거소지입니다.\"},\n",
    "        {\"output_answer\": \"비거주자의 소득세 납세지는 국내사업장의 소재지입니다. 국내사업장이 여러 곳인 경우 주된 사업장의 소재지가 납세지가 됩니다.\"},\n",
    "        {\"output_answer\": \"납세지가 불분명한 경우 대통령령으로 정합니다.\"},\n",
    "        {\"output_answer\": \"원천징수세액의 납세지는 원천징수자의 종류와 위치에 따라 결정됩니다.\"},\n",
    "        {\"output_answer\": \"납세자의 사망 시 상속인 또는 납세관리인의 주소지나 거소지가 납세지가 됩니다.\"},\n",
    "        {\"output_answer\": \"신탁 소득에 대한 납세의 범위는 신탁의 수익자가 해당 소득에 대해 납세의무를 집니다.\"},\n",
    "        {\"output_answer\": \"이자소득, 배당소득 및 기타 법에서 정한 소득은 원천징수 대상입니다.\"},\n",
    "        {\"output_answer\": \"공동 소유 자산의 양도소득은 각 거주자 소유 지분에 따라 과세됩니다.\"},\n",
    "        {\"output_answer\": \"이자 소득의 출처는 정부 및 지방자치단체가 발행한 채권, 법인이 발행한 채권, 국내외 은행 예금 등입니다.\"},\n",
    "        {\"output_answer\": \"배당소득은 국내외 법인으로부터 받는 배당금 및 배분금, 기타 법에서 정한 소득을 포함합니다.\"}\n",
    "    ],\n",
    "    metadata= [\n",
    "        {\"contexts\": \"제1조(목적) 이 법은 개인의 소득에 대하여 소득의 성격과 납세자의 부담능력 등에 따라 적정하게 과세함으로써 조세부담의 형평을 도모하고 재정수입의 원활한 조달에 이바지함을 목적으로 한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “거주자”란 국내에 주소를 두거나 183일 이상의 거소를 둔 개인을 말한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “비거주자”란 거주자가 아닌 개인을 말한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “내국법인”이란 「법인세법」 제2조제1호에 따른 내국법인을 말한다.\"},\n",
    "        {\"contexts\": \"제2조(납세의무) 거주자 및 국내원천소득이 있는 비거주자는 소득세를 납부할 의무가 있다.\"},\n",
    "        {\"contexts\": \"제3조(과세소득의 범위) 거주자는 법에서 규정한 모든 소득에 대해 과세되며, 비거주자는 국내원천소득에 대해서만 과세된다.\"},\n",
    "        {\"contexts\": \"제4조(소득의 구분) 소득은 종합소득, 퇴직소득, 양도소득으로 분류된다.\"},\n",
    "        {\"contexts\": \"제4조(소득의 구분) 종합소득은 이자소득, 배당소득, 사업소득, 근로소득, 연금소득 및 기타소득을 포함한다.\"},\n",
    "        {\"contexts\": \"제12조(비과세소득) 비과세 소득에는 공익신탁의 이익, 특정 사업소득 및 기타 법에서 정한 특정 소득이 포함된다.\"},\n",
    "        {\"contexts\": \"제5조(과세기간) 소득세의 과세기간은 매년 1월 1일부터 12월 31일까지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 거주자의 소득세 납세지는 주소지이며, 주소지가 없으면 거소지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 비거주자의 소득세 납세지는 국내사업장의 소재지이다. 국내사업장이 여러 곳인 경우 주된 사업장의 소재지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 납세지가 불분명한 경우에는 대통령령으로 정한다.\"},\n",
    "        {\"contexts\": \"제7조(원천징수 등의 경우의 납세지) 원천징수세액의 납세지는 원천징수자의 종류와 위치에 따라 결정된다.\"},\n",
    "        {\"contexts\": \"제8조(상속 등의 경우의 납세지) 납세자의 사망 시 상속인 또는 납세관리인의 주소지나 거소지가 납세지가 된다.\"},\n",
    "        {\"contexts\": \"제2조의3(신탁재산 귀속 소득에 대한 납세의무의 범위) 신탁 소득에 대한 납세의 범위는 신탁의 수익자가 해당 소득에 대해 납세의무를 진다.\"},\n",
    "        {\"contexts\": \"제14조(과세표준의 계산) 이자소득, 배당소득 및 기타 법에서 정한 소득은 원천징수 대상이다.\"},\n",
    "        {\"contexts\": \"제14조(과세표준의 계산) 공동 소유 자산의 양도소득은 각 거주자 소유 지분에 따라 과세된다.\"},\n",
    "        {\"contexts\": \"제16조(이자소득) 이자 소득의 출처는 정부 및 지방자치단체가 발행한 채권, 법인이 발행한 채권, 국내외 은행 예금 등이다.\"},\n",
    "        {\"contexts\": \"제17조(배당소득) 배당소득은 국내외 법인으로부터 받는 배당금 및 배분금, 기타 법에서 정한 소득을 포함한다.\"}\n",
    "    ],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fdea21",
   "metadata": {},
   "source": [
    "3. Retriever 생성\n",
    "Evaluation을 위한 Retriever 생성\n",
    "3.x 에서 생성한 Pinecone Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e20db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a05707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = 'tax-index-markdown'\n",
    "\n",
    "database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)\n",
    "retriever = database.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b163b",
   "metadata": {},
   "source": [
    "4. LLM 답변 생성을 위한 RagBot\n",
    "retriever와 OpenAI API를 활용한 RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff178680",
   "metadata": {},
   "outputs": [],
   "source": [
    "### RAG bot\n",
    "\n",
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "class RagBot:\n",
    "\n",
    "    def __init__(self, retriever, model: str = \"gpt-4o\"):\n",
    "        # 위에서 선언한 retriever를 할용해서 Retrieval 실행\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        # LangSmith 문법\n",
    "        self._client = wrap_openai(openai.Client())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    @traceable()\n",
    "    def invoke_llm(self, question, docs):\n",
    "        # `retrieve_docs()` 를 통해 가져온 문서들을 system prompt로 전달\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"당신은 한국의 소득세 전문가입니다.\"\n",
    "                    \"아래 소득세법을 참고해서 사용자의 질문에 답변해주세요.\\n\\n\"\n",
    "                    f\"## 소득세법\\n\\n{docs}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Evaluators 를 활용해서 `answer`와 `context`를 평가할 예정\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc) for doc in docs],\n",
    "        }\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        docs = self.retrieve_docs(question)\n",
    "        return self.invoke_llm(question, docs)\n",
    "\n",
    "rag_bot = RagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6ef555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변만 평가할 때 사용\n",
    "def predict_rag_answer(example: dict):\n",
    "    response = rag_bot.get_answer(example[\"input_question\"])\n",
    "    return {\"answer\": response[\"answer\"]}\n",
    "\n",
    "# Context를 활용해서 hallucination을 평가할 때 사용\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    response = rag_bot.get_answer(example[\"input_question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e28d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Grade prompt\n",
    "# 답변의 정확도를 측정하기위해 사용되는 프롬프트\n",
    "grade_prompt_answer_accuracy = prompt = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "# RAG 답변 성능을 측정하기 위한 evaluator\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "\n",
    "    # `example`이 데이터를 생성할 때 입력한 `Question-Answer` pair. `run`은 `RagBot`을 활용해서 생성한 LLM의 답변\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    reference = example.outputs[\"output_answer\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"correct_answer\": reference,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "439b4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade prompt\n",
    "# 답변이 사용자의 질문에 얼마나 도움되는지 판단하는 프롬프트\n",
    "grade_prompt_answer_helpfulness = prompt = hub.pull(\"langchain-ai/rag-answer-helpfulness\")\n",
    "\n",
    "# 답변이 사용자의 질문에 얼마나 도움되는지 판단하는 Evaluator\n",
    "def answer_helpfulness_evaluator(run, example) -> dict:\n",
    "\n",
    "    # 데이터셋의 답변과 비교하지 않고, 데이터셋의 질문에 대한 LLM의 답변의 가치를 평가함\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_answer_helpfulness | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_helpfulness_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "663c99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 할루시네이션 판단을 위한 프롬프트\n",
    "grade_prompt_hallucinations = prompt = hub.pull(\"langchain-ai/rag-answer-hallucination\")\n",
    "\n",
    "def answer_hallucination_evaluator(run, example) -> dict:\n",
    "    # 데이터셋에 있는 질문과, LLM이 답변을 생성할 때 사용한 context를 활용\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    contexts = run.outputs[\"contexts\"]\n",
    "\n",
    "    # LLM의 답변\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_hallucinations | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"documents\": contexts,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_hallucination\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff330c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context, # 어떤 함수를 활용해서 LLM 답변을 확인할지 지정, hallucination 판단 여부에 따라 `with_context` 사용\n",
    "    data=dataset_name, # Evaluation에 사용될 dataset의 이름\n",
    "    evaluators=[answer_evaluator, answer_helpfulness_evaluator, answer_hallucination_evaluator], # 실행할 Evaluator의 종류\n",
    "    experiment_prefix=\"inflearn-evaluator-lecture-hallucination\",\n",
    "    metadata={\"version\": \"income tax v1, gpt-4o\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a938e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
